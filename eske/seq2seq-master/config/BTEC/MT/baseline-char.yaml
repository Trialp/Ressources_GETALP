label: 'BTEC baseline'
description: "New BTEC baseline (beats Berard et al. 2016)"

cell_size: 256
attn_size: 256
embedding_size: 128

cell_type: LSTM
weight_scale: 0.1

data_dir: data/BTEC
model_dir: models/BTEC/MT/baseline_char
batch_size: 32
vocab_prefix: vocab.w2c

optimizer: adam
learning_rate: 0.001

steps_per_checkpoint: 2000
steps_per_eval: 2000
score_function: corpus_scores

max_gradient_norm: 1.0
batch_mode: standard
read_ahead: 10
max_len: 25
max_steps: 100000

encoders:
  - name: fr
    bidir_projection: True
    train_initial_states: False
    final_state: average

decoders:
  - name: en
    layers: 1
    max_len: 120
    embedding_size: 64
    character_level: True
    conditional_rnn: True
    pred_maxout_layer: False
    pred_deep_layer: True
    pred_deep_layer_size: 128
    use_previous_word: False
    pred_embed_proj: False

use_dropout: True
pervasive_dropout: True
rnn_input_dropout: 0.2
rnn_output_dropout: 0.2
attn_dropout: 0.2
word_dropout: 0.2
initial_state_dropout: 0.2
deep_layer_dropout: 0.2
